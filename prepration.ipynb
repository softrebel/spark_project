{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "\n",
    "# os.environ['PYSPARK_DRIVER_PYTHON_OPTS']= \"notebook\"\n",
    "# os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql.types import StructType,IntegerType,FloatType,BooleanType,StringType\n",
    "from pyspark.sql.functions import rand, count, isnull, when, col\n",
    "conf = SparkConf().setMaster(\"local[*]\").setAppName(\"My App\")\n",
    "sc = SparkContext.getOrCreate(conf = conf)\n",
    "sc._conf.set('spark.executor.memory','15g')\\\n",
    "    .set('spark.driver.memory','15g')\\\n",
    "        .set('spark.driver.maxResultsSize','0')\n",
    "spark=SparkSession.builder\\\n",
    "    .appName('myApp')\\\n",
    "        .config(\"spark.driver.memory\", \"15g\")\\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(files,schema):\n",
    "    df=spark.read.csv(files,header=True\n",
    "                  ,schema=schema)\n",
    "    return df\n",
    "\n",
    "def load_record_linkage_data():\n",
    "    schema = StructType() \\\n",
    "      .add(\"id_1\",IntegerType(),True) \\\n",
    "      .add(\"id_2\",IntegerType(),True) \\\n",
    "      .add(\"cmp_fname_c1\",FloatType(),True) \\\n",
    "      .add(\"cmp_fname_c2\",FloatType(),True) \\\n",
    "      .add(\"cmp_lname_c1\",FloatType(),True) \\\n",
    "      .add(\"cmp_lname_c2\",FloatType(),True) \\\n",
    "      .add(\"cmp_sex\",IntegerType(),True) \\\n",
    "      .add(\"cmp_bd\",IntegerType(),True) \\\n",
    "      .add(\"cmp_bm\",IntegerType(),True) \\\n",
    "      .add(\"cmp_by\",IntegerType(),True) \\\n",
    "      .add(\"cmp_plz\",IntegerType(),True) \\\n",
    "      .add(\"is_match\",BooleanType(),False)\n",
    "    files=[f'./data/block_{id}.csv' for id in range(1,11)]\n",
    "    return load_data(files,schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=load_record_linkage_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id_1: integer (nullable = true)\n",
      " |-- id_2: integer (nullable = true)\n",
      " |-- cmp_fname_c1: float (nullable = true)\n",
      " |-- cmp_fname_c2: float (nullable = true)\n",
      " |-- cmp_lname_c1: float (nullable = true)\n",
      " |-- cmp_lname_c2: float (nullable = true)\n",
      " |-- cmp_sex: integer (nullable = true)\n",
      " |-- cmp_bd: integer (nullable = true)\n",
      " |-- cmp_bm: integer (nullable = true)\n",
      " |-- cmp_by: integer (nullable = true)\n",
      " |-- cmp_plz: integer (nullable = true)\n",
      " |-- is_match: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+------------+------------+------------+------------+-------+------+------+------+-------+--------+\n",
      "| id_1| id_2|cmp_fname_c1|cmp_fname_c2|cmp_lname_c1|cmp_lname_c2|cmp_sex|cmp_bd|cmp_bm|cmp_by|cmp_plz|is_match|\n",
      "+-----+-----+------------+------------+------------+------------+-------+------+------+------+-------+--------+\n",
      "| 3148| 8326|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n",
      "|14055|94934|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n",
      "|33948|34740|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n",
      "|  946|71870|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n",
      "|64880|71676|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n",
      "|25739|45991|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n",
      "|62415|93584|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      0|    true|\n",
      "|27995|31399|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n",
      "| 4909|12238|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n",
      "|15161|16743|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n",
      "+-----+-----+------------+------------+------------+------------+-------+------+------+------+-------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## تبدیل به داده‌های عددی"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, lit\n",
    "\n",
    "\n",
    "def convert_label_binary(input_df):\n",
    "    temp = input_df.withColumn('label',\n",
    "                             when(input_df['is_match']==True,\n",
    "                                  lit(1)).otherwise(0)\n",
    "                                  ) \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_df = convert_label_binary(df).drop('is_match')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id_1: integer (nullable = true)\n",
      " |-- id_2: integer (nullable = true)\n",
      " |-- cmp_fname_c1: float (nullable = true)\n",
      " |-- cmp_fname_c2: float (nullable = true)\n",
      " |-- cmp_lname_c1: float (nullable = true)\n",
      " |-- cmp_lname_c2: float (nullable = true)\n",
      " |-- cmp_sex: integer (nullable = true)\n",
      " |-- cmp_bd: integer (nullable = true)\n",
      " |-- cmp_bm: integer (nullable = true)\n",
      " |-- cmp_by: integer (nullable = true)\n",
      " |-- cmp_plz: integer (nullable = true)\n",
      " |-- label: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "numerical_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+------------+------------+------------+------------+-------+------+------+------+-------+-----+\n",
      "| id_1| id_2|cmp_fname_c1|cmp_fname_c2|cmp_lname_c1|cmp_lname_c2|cmp_sex|cmp_bd|cmp_bm|cmp_by|cmp_plz|label|\n",
      "+-----+-----+------------+------------+------------+------------+-------+------+------+------+-------+-----+\n",
      "| 3148| 8326|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    1|\n",
      "|14055|94934|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    1|\n",
      "|33948|34740|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    1|\n",
      "|  946|71870|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    1|\n",
      "|64880|71676|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    1|\n",
      "|25739|45991|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    1|\n",
      "|62415|93584|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      0|    1|\n",
      "|27995|31399|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    1|\n",
      "| 4909|12238|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    1|\n",
      "|15161|16743|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    1|\n",
      "+-----+-----+------------+------------+------------+------------+-------+------+------+------+-------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "numerical_df.show(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+------------+------------+------------+------------+-------+------+------+------+-------+-----+\n",
      "|id_1|id_2|cmp_fname_c1|cmp_fname_c2|cmp_lname_c1|cmp_lname_c2|cmp_sex|cmp_bd|cmp_bm|cmp_by|cmp_plz|label|\n",
      "+----+----+------------+------------+------------+------------+-------+------+------+------+-------+-----+\n",
      "|   0|   0|        1007|     5645434|           0|     5746668|      0|   795|   795|   795|  12843|    0|\n",
      "+----+----+------------+------------+------------+------------+-------+------+------+------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "numerical_df.select([count(when(isnull(column), column)).alias(column) for column in numerical_df.columns]).show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Missing Values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_id_numerical_df = numerical_df.drop('id_1','id_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+------------+------------+-------+------+------+------+-------+-----+\n",
      "|cmp_fname_c1|cmp_fname_c2|cmp_lname_c1|cmp_lname_c2|cmp_sex|cmp_bd|cmp_bm|cmp_by|cmp_plz|label|\n",
      "+------------+------------+------------+------------+-------+------+------+------+-------+-----+\n",
      "|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    1|\n",
      "|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    1|\n",
      "|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    1|\n",
      "|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    1|\n",
      "|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    1|\n",
      "|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    1|\n",
      "|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      0|    1|\n",
      "|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    1|\n",
      "|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    1|\n",
      "|         1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    1|\n",
      "+------------+------------+------------+------------+-------+------+------+------+-------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "no_id_numerical_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5749132"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_id_numerical_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5749132"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_id_numerical_df.na.drop(how='all').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5749132"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_id_numerical_df.na.drop(how='any',thresh=2).count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill the Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "\n",
    "def fill_missing_values(input_df):\n",
    "    # for float variables\n",
    "    miss_df=input_df.drop('id_1','id_2')\n",
    "    miss_df=miss_df.replace('?',None)\n",
    "    float_cols=[\n",
    "    'cmp_fname_c1', \n",
    "    'cmp_fname_c2', \n",
    "    'cmp_lname_c1', \n",
    "    'cmp_lname_c2', \n",
    "    ]\n",
    "    float_imputer = Imputer(\n",
    "        inputCols=float_cols,\n",
    "        outputCols=[f\"{col}_imp\" for col in float_cols]\n",
    "    ).setStrategy('mean')\n",
    "\n",
    "    # for binary variables\n",
    "    binary_cols=[\n",
    "        'cmp_sex', \n",
    "        'cmp_bd', \n",
    "        'cmp_bm', \n",
    "        'cmp_by',\n",
    "        'cmp_plz',\n",
    "    ]\n",
    "    binary_imputer = Imputer(\n",
    "        inputCols=binary_cols,\n",
    "        outputCols=[f\"{col}_imp\" for col in binary_cols]\n",
    "    ).setStrategy('mode')\n",
    "    imputed_df=float_imputer.fit(miss_df).transform(miss_df)\n",
    "    output_df=binary_imputer.fit(imputed_df).transform(imputed_df)\n",
    "    output_df=output_df.select([x for x in output_df.columns if '_imp' in x or x=='is_match'])\n",
    "    return output_df\n",
    "\n",
    "\n",
    "def preprocessing_df(input_df):\n",
    "    output_df = convert_label_binary(fill_missing_values(input_df))\n",
    "    return output_df.drop('is_match')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_df=preprocessing_df(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+----------------+----------------+-----------+----------+----------+----------+-----------+-----+\n",
      "|cmp_fname_c1_imp|cmp_fname_c2_imp|cmp_lname_c1_imp|cmp_lname_c2_imp|cmp_sex_imp|cmp_bd_imp|cmp_bm_imp|cmp_by_imp|cmp_plz_imp|label|\n",
      "+----------------+----------------+----------------+----------------+-----------+----------+----------+----------+-----------+-----+\n",
      "|             1.0|       0.9000177|             1.0|      0.31841284|          1|         1|         1|         1|          1|    1|\n",
      "|             1.0|       0.9000177|             1.0|      0.31841284|          1|         1|         1|         1|          1|    1|\n",
      "|             1.0|       0.9000177|             1.0|      0.31841284|          1|         1|         1|         1|          1|    1|\n",
      "|             1.0|       0.9000177|             1.0|      0.31841284|          1|         1|         1|         1|          1|    1|\n",
      "|             1.0|       0.9000177|             1.0|      0.31841284|          1|         1|         1|         1|          1|    1|\n",
      "|             1.0|       0.9000177|             1.0|      0.31841284|          1|         1|         1|         1|          1|    1|\n",
      "|             1.0|       0.9000177|             1.0|      0.31841284|          1|         1|         1|         1|          0|    1|\n",
      "|             1.0|       0.9000177|             1.0|      0.31841284|          1|         1|         1|         1|          1|    1|\n",
      "|             1.0|       0.9000177|             1.0|      0.31841284|          1|         1|         1|         1|          1|    1|\n",
      "|             1.0|       0.9000177|             1.0|      0.31841284|          1|         1|         1|         1|          1|    1|\n",
      "+----------------+----------------+----------------+----------------+-----------+----------+----------+----------+-----------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prep_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+----------------+----------------+-----------+----------+----------+----------+-----------+-----+\n",
      "|cmp_fname_c1_imp|cmp_fname_c2_imp|cmp_lname_c1_imp|cmp_lname_c2_imp|cmp_sex_imp|cmp_bd_imp|cmp_bm_imp|cmp_by_imp|cmp_plz_imp|label|\n",
      "+----------------+----------------+----------------+----------------+-----------+----------+----------+----------+-----------+-----+\n",
      "|               0|               0|               0|               0|          0|         0|         0|         0|          0|    0|\n",
      "+----------------+----------------+----------------+----------------+-----------+----------+----------+----------+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prep_df.select([count(when(isnull(column), column)).alias(column) for column in prep_df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "def feature_engineering(input_df,feature_list,label_name):\n",
    "    assembler = VectorAssembler(inputCols=feature_list,\n",
    "                             outputCol='features')\n",
    "    assembled_df = assembler.transform(input_df)\n",
    "    output_df=assembled_df.select('features', label_name)\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cmp_bm_imp',\n",
       " 'cmp_by_imp',\n",
       " 'cmp_bd_imp',\n",
       " 'cmp_fname_c1_imp',\n",
       " 'cmp_fname_c2_imp',\n",
       " 'cmp_lname_c2_imp',\n",
       " 'cmp_sex_imp',\n",
       " 'cmp_lname_c1_imp',\n",
       " 'cmp_plz_imp']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_features=list(set(prep_df.columns) - set(['label','is_match']))\n",
    "input_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------+-----+\n",
      "|features                                                           |label|\n",
      "+-------------------------------------------------------------------+-----+\n",
      "|[1.0,1.0,1.0,1.0,0.9000176787376404,0.3184128403663635,1.0,1.0,1.0]|1    |\n",
      "|[1.0,1.0,1.0,1.0,0.9000176787376404,0.3184128403663635,1.0,1.0,1.0]|1    |\n",
      "|[1.0,1.0,1.0,1.0,0.9000176787376404,0.3184128403663635,1.0,1.0,1.0]|1    |\n",
      "|[1.0,1.0,1.0,1.0,0.9000176787376404,0.3184128403663635,1.0,1.0,1.0]|1    |\n",
      "|[1.0,1.0,1.0,1.0,0.9000176787376404,0.3184128403663635,1.0,1.0,1.0]|1    |\n",
      "|[1.0,1.0,1.0,1.0,0.9000176787376404,0.3184128403663635,1.0,1.0,1.0]|1    |\n",
      "|[1.0,1.0,1.0,1.0,0.9000176787376404,0.3184128403663635,1.0,1.0,0.0]|1    |\n",
      "|[1.0,1.0,1.0,1.0,0.9000176787376404,0.3184128403663635,1.0,1.0,1.0]|1    |\n",
      "|[1.0,1.0,1.0,1.0,0.9000176787376404,0.3184128403663635,1.0,1.0,1.0]|1    |\n",
      "|[1.0,1.0,1.0,1.0,0.9000176787376404,0.3184128403663635,1.0,1.0,1.0]|1    |\n",
      "+-------------------------------------------------------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "assembled_df = feature_engineering(prep_df,input_features,'label')\n",
    "assembled_df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train_split(input_df,train_size=0.7):\n",
    "    train, test = assembled_df.randomSplit([train_size,1 - train_size], seed=42)\n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = test_train_split(assembled_df,0.7)\n",
    "train.count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator,MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import DecisionTreeClassifier,LogisticRegression\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np\n",
    "def evaluate_from_scratch(pred,model_name='Logistic Regression'):\n",
    "    pred.groupBy('label', 'prediction').count().show()\n",
    "\n",
    "    # Calculate the elements of the confusion matrix\n",
    "    TN = pred.filter('prediction = 0 AND label = prediction').count()\n",
    "    TP = pred.filter('prediction = 1 AND label = prediction').count()\n",
    "    FN = pred.filter('prediction = 0 AND label = 1').count()\n",
    "    FP = pred.filter('prediction = 1 AND label = 0').count()\n",
    "\n",
    "    # Accuracy measures the proportion of correct predictions\n",
    "    accuracy = (TN + TP) / (TN + TP + FN + FP)\n",
    "    recall = (TP) / (TP+FN)\n",
    "    precision= (TP) / (TP+FP)\n",
    "    f1=2*(precision*recall)/(precision+recall)\n",
    "    print(f'EVALUATION SUMMARY for {model_name}:')\n",
    "    print(f\" accuracy:{accuracy}\")\n",
    "    print(f\" precision:{precision}\")\n",
    "    print(f\" recall:{recall}\")\n",
    "    print(f\" f1-score:{f1}\")\n",
    "\n",
    "def evaluate_from_spark(predictions,model_name='Logistic Regression'):\n",
    "    eval = BinaryClassificationEvaluator(rawPredictionCol=\"probability\", labelCol=\"label\")\n",
    "    eval2= MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\")\n",
    "    AUC  = eval.evaluate(predictions)\n",
    "    ACC  = eval2.evaluate(predictions, {eval2.metricName:\"accuracy\"})\n",
    "    PREC  = eval2.evaluate(predictions, {eval2.metricName:\"weightedPrecision\"})\n",
    "    REC  = eval2.evaluate(predictions, {eval2.metricName:\"weightedRecall\"})\n",
    "    F1  = eval2.evaluate(predictions, {eval2.metricName:\"f1\"})\n",
    "    WeightedFMeasure=eval2.evaluate(predictions, {eval2.metricName:\"weightedFMeasure\"})\n",
    "    print(f\"{model_name} Performance Measure\")\n",
    "    print(\" Accuracy = %0.8f\" % ACC)\n",
    "    print(\" Weighted Precision = %0.8f\" % PREC)\n",
    "    print(\" Weighted Recall = %0.8f\" % REC)\n",
    "    print(\" F1 = %0.8f\" % F1)\n",
    "    print(\" Weighted F Measure = %0.8f\" % WeightedFMeasure)\n",
    "\n",
    "    print(\" AUC = %.8f\" % AUC)\n",
    "    print(\" ROC curve:\")\n",
    "    PredAndLabels           = predictions.select(\"probability\", \"label\")\n",
    "    PredAndLabels_collect   = PredAndLabels.collect()\n",
    "    PredAndLabels_list      = [(float(i[0][0]), 1.0-float(i[1])) for i in PredAndLabels_collect]\n",
    "    PredAndLabels           = sc.parallelize(PredAndLabels_list)\n",
    "    fpr = dict()                                                        # FPR: False Positive Rate\n",
    "    tpr = dict()                                                        # TPR: True Positive Rate\n",
    "    roc_auc = dict()\n",
    "    \n",
    "    y_test = [i[1] for i in PredAndLabels_list]\n",
    "    y_score = [i[0] for i in PredAndLabels_list]\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure(figsize=(5,4))\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.8f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'r--')\n",
    "    # plt.xlim([0.0, 1.0])\n",
    "    # plt.ylim([0.0, 1.05])\n",
    "    plt.yticks(np.arange(0,1.03,0.1))\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - {model_name}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "\n",
    "def evaluate(predictions,model_name=None):\n",
    "    print('Evaluate From Scratch:')\n",
    "    evaluate_from_scratch(predictions,model_name)\n",
    "    print('\\nEvaluate From Spark Library:')\n",
    "    evaluate_from_spark(predictions,model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr=LogisticRegression(featuresCol='features', labelCol='label')\n",
    "# lr_model = lr.fit(train)\n",
    "# lr_result = lr_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LogisticRegression(featuresCol='features', labelCol='label')\n",
    "pipeline = Pipeline(stages=[lr])\n",
    "model = pipeline.fit(train)\n",
    "lr_result = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_result.select('label', 'prediction', 'probability').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(lr_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier()\n",
    "tree_pipeline = Pipeline(stages=[tree])\n",
    "tree_model = tree_pipeline.fit(train)\n",
    "tree_result = tree_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(tree_result,model_name='Decision Tree')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "rf_pipeline = Pipeline(stages=[ rf])\n",
    "rf_model=rf_pipeline.fit(train)\n",
    "rf_result=rf_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(rf_result,model_name='Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Not Refactored yet...\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder, CrossValidatorModel\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_cs = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr_cs = LogisticRegression()\n",
    "grid = ParamGridBuilder().addGrid(lr_cs.regParam, [0.1, 0.01]) \\\n",
    "    .addGrid(lr_cs.fitIntercept, [False, True])\\\n",
    "    .addGrid(lr_cs.elasticNetParam, [0.0, 1.0])\\\n",
    "    .build()\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "cv = CrossValidator(estimator=lr_cs, estimatorParamMaps=grid, evaluator=evaluator)\n",
    "cvModel = cv.fit(train)\n",
    "lrprediction=cvModel.transform(test)\n",
    "\n",
    "\n",
    "\n",
    "print('Accuracy:', evaluator.evaluate(lrprediction))\n",
    "print('AUC:', BinaryClassificationMetrics(lrprediction['label','prediction'].rdd).areaUnderROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(lrprediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "grid = ParamGridBuilder() \\\n",
    "        .addGrid(dt.maxDepth,  [2, 5, 10, 20, 30]) \\\n",
    "        .addGrid(dt.maxBins,  [10, 20, 40, 80, 100]) \\\n",
    "        .build()\n",
    "dtevaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "cv = CrossValidator(estimator=dt, \n",
    "                    estimatorParamMaps=grid, \n",
    "                    evaluator=dtevaluator,\n",
    "                    numFolds = 3)\n",
    "dtModel = cv.fit(train)\n",
    "dtpredictions = dtModel.transform(test)\n",
    "\n",
    "print('Accuracy:', dtevaluator.evaluate(dtpredictions))\n",
    "print('AUC:', BinaryClassificationMetrics(dtpredictions['label','prediction'].rdd).areaUnderROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(dtpredictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f806c54240dae2e322067c5e8fc2986bf76c93cd7a500f8e3af4a5be5065965"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
